{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ff3d30-7380-49ea-886c-975f378152ee",
   "metadata": {},
   "source": [
    "### Classifying the images based on various disease of images"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:26:52.661712Z",
     "start_time": "2024-08-09T19:26:48.786112Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install timm",
   "id": "b1f0290042e8f4a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mDEPRECATION: Loading egg at /Users/mac/anaconda3/lib/python3.11/site-packages/python_docx-1.1.2-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mDEPRECATION: Loading egg at /Users/mac/anaconda3/lib/python3.11/site-packages/Pattern-3.6.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting timm\r\n",
      "  Using cached timm-1.0.8-py3-none-any.whl.metadata (53 kB)\r\n",
      "Requirement already satisfied: torch in /Users/mac/anaconda3/lib/python3.11/site-packages (from timm) (2.3.1)\r\n",
      "Requirement already satisfied: torchvision in /Users/mac/anaconda3/lib/python3.11/site-packages (from timm) (0.18.1)\r\n",
      "Requirement already satisfied: pyyaml in /Users/mac/anaconda3/lib/python3.11/site-packages (from timm) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface_hub in /Users/mac/anaconda3/lib/python3.11/site-packages (from timm) (0.23.4)\r\n",
      "Requirement already satisfied: safetensors in /Users/mac/anaconda3/lib/python3.11/site-packages (from timm) (0.4.2)\r\n",
      "Requirement already satisfied: filelock in /Users/mac/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mac/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.6.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mac/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (24.1)\r\n",
      "Requirement already satisfied: requests in /Users/mac/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/mac/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mac/anaconda3/lib/python3.11/site-packages (from huggingface_hub->timm) (4.12.1)\r\n",
      "Requirement already satisfied: sympy in /Users/mac/anaconda3/lib/python3.11/site-packages (from torch->timm) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/mac/anaconda3/lib/python3.11/site-packages (from torch->timm) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /Users/mac/anaconda3/lib/python3.11/site-packages (from torch->timm) (3.1.4)\r\n",
      "Requirement already satisfied: numpy in /Users/mac/anaconda3/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/mac/anaconda3/lib/python3.11/site-packages (from torchvision->timm) (10.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mac/anaconda3/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2024.7.4)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mac/anaconda3/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\r\n",
      "Using cached timm-1.0.8-py3-none-any.whl (2.3 MB)\r\n",
      "\u001B[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001B[0m\u001B[33m\r\n",
      "\u001B[0mInstalling collected packages: timm\r\n",
      "Successfully installed timm-1.0.8\r\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:21:30.043308Z",
     "start_time": "2024-08-12T17:21:30.013340Z"
    }
   },
   "cell_type": "code",
   "source": "import timm",
   "id": "a63719d5498417e2",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:16:24.740774Z",
     "start_time": "2024-08-12T17:16:24.730750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models_path = {\n",
    "    'Vit-Model': 'models/vit_base_patch16_224_best.pth',\n",
    "    'Efficientnet': 'models/efficientnet_b0_best.pth',\n",
    "    'Densenet': 'models/densenet121_best.pth',\n",
    "    'Resnet50': 'models/resnet50_best.pth'\n",
    "}"
   ],
   "id": "e7bb22463b7c763c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "24d56646-5f08-4454-8a22-27cd920b9de6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:18:00.225830Z",
     "start_time": "2024-08-12T17:17:59.527277Z"
    }
   },
   "source": [
    "# Define the classes\n",
    "classes = [\n",
    "    \"Diabetes\",\n",
    "    \"Normal Fundus\",\n",
    "    \"Cataract\"\n",
    "]\n",
    "\n",
    "\n",
    "def classify(model, model_name, image_path, classes):\n",
    "    # Define the mean and std for normalization\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # Define image transformations\n",
    "    image_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "    ])\n",
    "\n",
    "    model = model.eval()\n",
    "    from PIL import Image\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB mode\n",
    "    image = image_transforms(image).float()\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "    print(f\"{model_name} -> \", classes[predicted.item()])\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:43:36.269107Z",
     "start_time": "2024-08-09T19:43:36.266488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_vit_model():\n",
    "    # Initialize the Vision Transformer (ViT) model architecture\n",
    "    vit_model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "    num_classes = len(classes)\n",
    "    vit_model.head = torch.nn.Linear(vit_model.head.in_features, num_classes)\n",
    "\n",
    "    # Load the saved state dictionary\n",
    "    vit_model.load_state_dict(torch.load(models_path.get('Vit-Model'), map_location=torch.device('cpu')))\n",
    "\n",
    "    print('Vit-Model loaded successfully')\n",
    "    return vit_model"
   ],
   "id": "829bf13e5d6e87ed",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:43:38.725145Z",
     "start_time": "2024-08-09T19:43:36.957376Z"
    }
   },
   "cell_type": "code",
   "source": "vit_model = load_vit_model()",
   "id": "9734d3bf-4cc3-48dc-8abc-25ae8e692c6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vit-Model loaded successfully\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:15:48.009212Z",
     "start_time": "2024-08-12T17:15:46.728282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_efficientnet_model():\n",
    "    # Initialize the EfficientNet-B0 model architecture\n",
    "    efficientnet_model = models.efficientnet_b0(pretrained=False)\n",
    "    num_classes = len(classes)\n",
    "    efficientnet_model.classifier[1] = torch.nn.Linear(efficientnet_model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    # Load the saved state dictionary\n",
    "    efficientnet_model.load_state_dict(torch.load(models_path.get('Efficientnet'), map_location=torch.device('cpu')))\n",
    "\n",
    "    print('Efficientnet loaded successfully')\n",
    "    return efficientnet_model"
   ],
   "id": "83eab8a17cdc9e4d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:44:01.574026Z",
     "start_time": "2024-08-09T19:44:01.462921Z"
    }
   },
   "cell_type": "code",
   "source": "efficientnet_model = load_efficientnet_model()",
   "id": "4c856681-9b0a-472c-a7cd-af08950706b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficientnet loaded successfully\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:44:10.078450Z",
     "start_time": "2024-08-09T19:44:10.073638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_densenet_model():\n",
    "    # Initialize the DenseNet model architecture\n",
    "    densenet_model = models.densenet121(pretrained=False)\n",
    "    num_classes = len(classes)\n",
    "    densenet_model.classifier = torch.nn.Linear(densenet_model.classifier.in_features, num_classes)\n",
    "\n",
    "    # Load the saved state dictionary\n",
    "    densenet_model.load_state_dict(torch.load(models_path.get('Densenet'), map_location=torch.device('cpu')))\n",
    "\n",
    "    print('Densenet loaded successfully')\n",
    "    return densenet_model"
   ],
   "id": "306b4fb9ce687214",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:44:13.912208Z",
     "start_time": "2024-08-09T19:44:13.673695Z"
    }
   },
   "cell_type": "code",
   "source": "densenet_model = load_densenet_model()",
   "id": "0b057d13-b3d6-42d4-9a26-935e07407e43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densenet loaded successfully\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:16:58.358115Z",
     "start_time": "2024-08-12T17:16:58.352816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_resnet_model():\n",
    "    # Initialize the ResNet-50 model architecture\n",
    "    resnet_model = models.resnet50(pretrained=False)\n",
    "    num_classes = len(classes)\n",
    "    resnet_model.fc = torch.nn.Linear(resnet_model.fc.in_features, num_classes)\n",
    "\n",
    "    # Load the saved state dictionary\n",
    "    resnet_model.load_state_dict(torch.load(models_path.get('Resnet50'), map_location=torch.device('cpu')))\n",
    "\n",
    "    print('Resnet50 loaded successfully')\n",
    "    return resnet_model"
   ],
   "id": "4ff60c3e533fc89f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:17:00.917199Z",
     "start_time": "2024-08-12T17:17:00.317307Z"
    }
   },
   "cell_type": "code",
   "source": "resnet_model = load_resnet_model()",
   "id": "9b5682fd-080d-4f70-893c-3c5d45db3408",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 loaded successfully\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "139e5243-4011-42c3-b7f3-a77d7d9b5619"
  },
  {
   "cell_type": "code",
   "id": "1eeeac02-edb5-4ec9-ad46-bf9c4b5ecfcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:18:05.581483Z",
     "start_time": "2024-08-12T17:18:05.195133Z"
    }
   },
   "source": [
    "image_path = \"./images/diabetes_1.jpg\"\n",
    "# classify(densenet_model, \"Densenet\", image_path, classes)\n",
    "# classify(efficientnet_model, \"Efficientnet\", image_path, classes)\n",
    "# classify(vit_model, \"Vit-Model\", image_path, classes)\n",
    "classify(resnet_model, \"Resnet50\", image_path, classes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 ->  Normal Fundus\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "71792932-b513-4012-848d-e2545ed99060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:37:40.247024Z",
     "start_time": "2024-08-09T19:37:39.700699Z"
    }
   },
   "source": [
    "image_path = \"./images/fundus_2.jpg\"\n",
    "classify(densenet_model, \"Densenet\", image_path, classes)\n",
    "classify(efficientnet_model, \"Efficientnet\", image_path, classes)\n",
    "classify(vit_model, \"Vit-Model\", image_path, classes)\n",
    "classify(resnet_model, \"Resnet50\", image_path, classes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densenet ->  Cataract\n",
      "Efficientnet ->  Normal Fundus\n",
      "Vit-Model ->  Cataract\n",
      "Resnet50 ->  Normal Fundus\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "88afd4c5-db27-4c3e-bc48-08ed8ced3239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T17:19:35.996706Z",
     "start_time": "2024-08-12T17:19:35.970932Z"
    }
   },
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Define the classes\n",
    "classes = [\n",
    "    \"Cataract\",\n",
    "    \"Diabetes\",\n",
    "    \"Glaucoma\",\n",
    "]\n",
    "\n",
    "\n",
    "# @st.cache_resource\n",
    "def load_resnet_model():\n",
    "    # Initialize the ResNet-50 model architecture\n",
    "    resnet_model = models.resnet50(pretrained=False)\n",
    "    num_classes = len(classes)\n",
    "    resnet_model.fc = torch.nn.Linear(resnet_model.fc.in_features, num_classes)\n",
    "\n",
    "    # Load the saved state dictionary\n",
    "    resnet_model.load_state_dict(torch.load('models/resnet50_best.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "    print('Resnet50 loaded successfully')\n",
    "    return resnet_model\n",
    "\n",
    "\n",
    "# Load the model\n",
    "resnet_model = load_resnet_model()()\n",
    "\n",
    "\n",
    "def classify_eye(model, image):\n",
    "    model = model.eval()\n",
    "\n",
    "    # Define image transformations\n",
    "    image_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image = image.convert('RGB')  # Ensure the image is in RGB mode\n",
    "    image = image_transforms(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move model and image to the appropriate device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "    return classes[predicted.item()]\n",
    "\n",
    "\n",
    "st.title(\"Eye Image Classification\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Upload an image of an eye\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
    "    st.write(\"\")\n",
    "\n",
    "    if st.button('Classify Image'):\n",
    "        result = classify_eye(resnet_model, image)\n",
    "        st.write(f\"Prediction: {result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T19:54:49.520386Z",
     "start_time": "2024-08-09T19:54:49.517850Z"
    }
   },
   "cell_type": "code",
   "source": "# !streamlit run app.py",
   "id": "b3c646dc5add81da",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9bddc36708e071ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
